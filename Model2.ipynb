{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8246c088-b3c4-4923-b9d2-8c2cf2a75832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2aec729-77af-4b2e-baf1-724dc247e0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/hour.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e3c282b-e9bc-416c-a189-08215ab3beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def features and dropping\n",
    "\n",
    "categorical_columns = ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "numerical_columns = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "target_column = 'cnt'\n",
    "columns_to_drop = ['instant', 'dteday', 'casual', \"registered\"]\n",
    "data_cleaned = data.drop(columns=columns_to_drop, errors='ignore') #drop the data that we will not use\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7dae68a-47f0-4e1f-8e50-6137d1123e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OHE\n",
    "\n",
    "X_processed_df = pd.get_dummies(data_cleaned, columns=categorical_columns, drop_first=True) #OHE\n",
    "Y_series = X_processed_df.pop(target_column) #extract cnt and remove it from X_processed\n",
    "X_df = X_processed_df # x contains all features\n",
    "\n",
    "#X_df = X_df.reset_index(drop=True)\n",
    "#Y_series = Y_series.reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e885eb27-f936-47cf-bb94-6df8ebce2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60-20-20 split\n",
    "\n",
    "m = len(X_df)\n",
    "train_end = int(m*0.6)\n",
    "val_end = int(m*0.8)\n",
    "\n",
    "X_train_df = X_df.iloc[:train_end]\n",
    "y_train = Y_series.iloc[:train_end].values\n",
    "\n",
    "X_val_df = X_df.iloc[train_end:val_end]\n",
    "y_val = Y_series.iloc[train_end:val_end].values\n",
    "\n",
    "X_test_df = X_df.iloc[val_end:]\n",
    "y_test = Y_series.iloc[val_end:].values\n",
    "\n",
    "\n",
    "#conversion to numpy arrays for using keras (as floats)\n",
    "\n",
    "X_train_processed = X_train_df.values.astype('float32')\n",
    "X_val_processed = X_val_df.values.astype('float32')\n",
    "X_test_processed = X_test_df.values.astype('float32')\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_val = y_val.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "340b71f2-7489-44d6-b05b-c090333acee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ L1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ L2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ L3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ L1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m2,700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ L2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m1,275\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ L3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m26\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,001</span> (15.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,001\u001b[0m (15.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,001</span> (15.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,001\u001b[0m (15.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# deep learning model\n",
    "\n",
    "input_shape = X_train_processed.shape[1] #nr features\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(input_shape,)),    #specify input size\n",
    "        Dense(50, activation='relu', name = \"L1\"), \n",
    "        Dense(25, activation='relu', name = \"L2\"), \n",
    "        Dense(1, activation='linear', name = \"L3\")\n",
    "    ]\n",
    ")\n",
    "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics = [\"mae\"]\n",
    "             )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c91c43c-becb-4128-a584-7b61c0d79a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 34245.0469 - mae: 133.7070 - val_loss: 44557.4609 - val_mae: 158.0275\n",
      "Epoch 2/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 11705.1475 - mae: 83.7550 - val_loss: 26428.7852 - val_mae: 121.0235\n",
      "Epoch 3/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6840.6816 - mae: 59.8026 - val_loss: 19001.5977 - val_mae: 105.5898\n",
      "Epoch 4/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5774.6138 - mae: 54.4068 - val_loss: 17490.3086 - val_mae: 103.5163\n",
      "Epoch 5/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5452.8120 - mae: 52.2888 - val_loss: 16866.2070 - val_mae: 100.2439\n",
      "Epoch 6/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5302.2861 - mae: 51.5101 - val_loss: 16211.5352 - val_mae: 96.5865\n",
      "Epoch 7/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4846.3794 - mae: 49.1789 - val_loss: 15618.1045 - val_mae: 96.5040\n",
      "Epoch 8/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4475.7578 - mae: 47.1029 - val_loss: 14860.8262 - val_mae: 93.8142\n",
      "Epoch 9/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4407.8184 - mae: 46.1818 - val_loss: 14185.6514 - val_mae: 93.0171\n",
      "Epoch 10/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3992.4888 - mae: 44.0831 - val_loss: 13662.7783 - val_mae: 92.7707\n",
      "Epoch 11/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3482.8555 - mae: 41.2501 - val_loss: 12259.7344 - val_mae: 86.0663\n",
      "Epoch 12/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3245.1428 - mae: 39.3294 - val_loss: 11348.5654 - val_mae: 82.7012\n",
      "Epoch 13/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2795.0234 - mae: 36.5194 - val_loss: 10688.5205 - val_mae: 80.6904\n",
      "Epoch 14/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2527.0757 - mae: 34.5336 - val_loss: 9824.7588 - val_mae: 76.7765\n",
      "Epoch 15/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2454.5469 - mae: 33.4747 - val_loss: 9405.9102 - val_mae: 75.3278\n",
      "Epoch 16/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2235.3291 - mae: 31.8238 - val_loss: 8637.6768 - val_mae: 71.1753\n",
      "Epoch 17/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1984.1279 - mae: 30.1940 - val_loss: 8265.3633 - val_mae: 68.9780\n",
      "Epoch 18/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1960.5557 - mae: 29.8147 - val_loss: 7795.6206 - val_mae: 66.3003\n",
      "Epoch 19/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1833.0616 - mae: 28.7083 - val_loss: 8088.4214 - val_mae: 69.2052\n",
      "Epoch 20/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1797.0627 - mae: 28.0423 - val_loss: 7447.9507 - val_mae: 64.4317\n",
      "Epoch 21/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1741.8177 - mae: 27.4653 - val_loss: 7678.0386 - val_mae: 66.4814\n",
      "Epoch 22/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1646.5651 - mae: 26.5436 - val_loss: 7388.1216 - val_mae: 64.6092\n",
      "Epoch 23/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1569.1455 - mae: 25.8736 - val_loss: 7134.6318 - val_mae: 62.6250\n",
      "Epoch 24/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1553.8466 - mae: 25.6675 - val_loss: 6839.7988 - val_mae: 60.7633\n",
      "Epoch 25/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1494.2516 - mae: 24.9286 - val_loss: 6934.4351 - val_mae: 61.6872\n",
      "Epoch 26/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1502.7667 - mae: 25.3561 - val_loss: 6731.1206 - val_mae: 60.3090\n",
      "Epoch 27/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1423.5240 - mae: 24.5975 - val_loss: 6412.8818 - val_mae: 57.6544\n",
      "Epoch 28/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1456.8099 - mae: 24.5015 - val_loss: 6615.6675 - val_mae: 59.2829\n",
      "Epoch 29/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1457.6052 - mae: 24.2343 - val_loss: 6373.9399 - val_mae: 57.4805\n",
      "Epoch 30/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1536.1714 - mae: 24.5964 - val_loss: 6492.5601 - val_mae: 58.6738\n",
      "Epoch 31/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1473.7075 - mae: 24.5538 - val_loss: 6363.5571 - val_mae: 57.9432\n",
      "Epoch 32/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1407.5341 - mae: 23.8049 - val_loss: 6364.2817 - val_mae: 57.7740\n",
      "Epoch 33/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1395.7809 - mae: 23.6260 - val_loss: 6227.4297 - val_mae: 57.0916\n",
      "Epoch 34/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1424.9423 - mae: 23.8252 - val_loss: 6131.4707 - val_mae: 56.2975\n",
      "Epoch 35/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1405.2875 - mae: 24.0400 - val_loss: 6121.6812 - val_mae: 56.7418\n",
      "Epoch 36/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1300.0609 - mae: 23.1004 - val_loss: 5989.8228 - val_mae: 55.5494\n",
      "Epoch 37/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1275.2557 - mae: 22.9406 - val_loss: 6390.8125 - val_mae: 58.2379\n",
      "Epoch 38/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1277.9071 - mae: 23.1535 - val_loss: 6103.1162 - val_mae: 56.3001\n",
      "Epoch 39/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1270.5144 - mae: 23.0920 - val_loss: 6146.2515 - val_mae: 56.6173\n",
      "Epoch 40/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1271.7345 - mae: 22.7916 - val_loss: 6236.2612 - val_mae: 57.2318\n",
      "Epoch 41/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1276.6387 - mae: 22.9564 - val_loss: 6088.1665 - val_mae: 56.3096\n",
      "Epoch 42/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1318.8759 - mae: 23.1452 - val_loss: 5951.3657 - val_mae: 55.3779\n",
      "Epoch 43/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1301.2626 - mae: 22.9835 - val_loss: 5951.8003 - val_mae: 55.5012\n",
      "Epoch 44/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1316.8878 - mae: 22.6456 - val_loss: 5887.1030 - val_mae: 55.2342\n",
      "Epoch 45/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1232.0012 - mae: 22.2743 - val_loss: 5869.3955 - val_mae: 55.0766\n",
      "Epoch 46/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1241.9789 - mae: 22.2012 - val_loss: 5849.2358 - val_mae: 54.7331\n",
      "Epoch 47/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1225.1825 - mae: 22.4215 - val_loss: 5870.7554 - val_mae: 55.0950\n",
      "Epoch 48/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1293.0587 - mae: 22.6049 - val_loss: 5797.6592 - val_mae: 54.4427\n",
      "Epoch 49/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1283.3320 - mae: 22.2565 - val_loss: 5712.3428 - val_mae: 54.0627\n",
      "Epoch 50/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1247.0087 - mae: 22.5579 - val_loss: 5853.9580 - val_mae: 55.2445\n",
      "Epoch 51/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1161.9999 - mae: 21.9513 - val_loss: 5681.1899 - val_mae: 53.9436\n",
      "Epoch 52/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1264.5890 - mae: 22.2093 - val_loss: 5698.1807 - val_mae: 53.9736\n",
      "Epoch 53/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1191.3237 - mae: 21.8711 - val_loss: 5704.0513 - val_mae: 54.0522\n",
      "Epoch 54/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1241.1382 - mae: 22.1328 - val_loss: 5780.9282 - val_mae: 54.8973\n",
      "Epoch 55/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1159.2585 - mae: 21.6941 - val_loss: 5868.5117 - val_mae: 55.5946\n",
      "Epoch 56/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1230.5122 - mae: 22.2912 - val_loss: 5651.1431 - val_mae: 54.2971\n",
      "Epoch 57/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1173.7063 - mae: 21.9689 - val_loss: 5632.7651 - val_mae: 53.9313\n",
      "Epoch 58/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1130.3247 - mae: 21.5897 - val_loss: 5653.9639 - val_mae: 54.3281\n",
      "Epoch 59/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1120.0619 - mae: 21.5563 - val_loss: 5664.5884 - val_mae: 53.8398\n",
      "Epoch 60/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1123.7040 - mae: 21.4323 - val_loss: 5634.0640 - val_mae: 53.7524\n",
      "Epoch 61/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1161.3636 - mae: 21.6609 - val_loss: 5745.4487 - val_mae: 54.8355\n",
      "Epoch 62/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1144.2965 - mae: 21.5101 - val_loss: 5581.4868 - val_mae: 53.7202\n",
      "Epoch 63/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1107.3336 - mae: 21.1264 - val_loss: 5628.3462 - val_mae: 53.9174\n",
      "Epoch 64/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1167.1708 - mae: 21.6520 - val_loss: 5629.0654 - val_mae: 54.1523\n",
      "Epoch 65/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1153.9253 - mae: 21.4045 - val_loss: 5527.5767 - val_mae: 53.1323\n",
      "Epoch 66/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1197.7521 - mae: 21.7137 - val_loss: 5541.3857 - val_mae: 53.3000\n",
      "Epoch 67/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1179.1233 - mae: 21.2398 - val_loss: 5532.5156 - val_mae: 52.9945\n",
      "Epoch 68/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1082.6869 - mae: 21.3680 - val_loss: 5569.5376 - val_mae: 53.6094\n",
      "Epoch 69/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1224.2234 - mae: 21.5158 - val_loss: 5592.5493 - val_mae: 54.1639\n",
      "Epoch 70/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1131.3983 - mae: 21.3901 - val_loss: 5501.9150 - val_mae: 52.8441\n",
      "Epoch 71/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1125.0739 - mae: 21.0420 - val_loss: 5467.2612 - val_mae: 52.6088\n",
      "Epoch 72/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1087.4789 - mae: 20.7170 - val_loss: 5500.4688 - val_mae: 52.6539\n",
      "Epoch 73/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1103.5765 - mae: 21.0375 - val_loss: 5493.5811 - val_mae: 53.0457\n",
      "Epoch 74/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1068.6608 - mae: 20.7602 - val_loss: 5420.2202 - val_mae: 52.2883\n",
      "Epoch 75/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1109.4662 - mae: 20.8913 - val_loss: 5565.7900 - val_mae: 52.8113\n",
      "Epoch 76/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1121.4650 - mae: 20.9777 - val_loss: 5515.9136 - val_mae: 52.5354\n",
      "Epoch 77/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1042.4969 - mae: 20.6059 - val_loss: 5445.7026 - val_mae: 52.2266\n",
      "Epoch 78/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1065.4066 - mae: 20.6812 - val_loss: 5497.4546 - val_mae: 52.6236\n",
      "Epoch 79/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1080.2751 - mae: 20.8733 - val_loss: 5354.4990 - val_mae: 52.4960\n",
      "Epoch 80/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1166.7614 - mae: 20.8899 - val_loss: 5279.4688 - val_mae: 51.5676\n",
      "Epoch 81/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1112.7087 - mae: 20.7731 - val_loss: 5365.6270 - val_mae: 52.0469\n",
      "Epoch 82/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1043.4628 - mae: 20.6376 - val_loss: 5355.3682 - val_mae: 52.2044\n",
      "Epoch 83/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1072.8439 - mae: 20.6496 - val_loss: 5457.6592 - val_mae: 51.9840\n",
      "Epoch 84/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1047.5459 - mae: 20.7976 - val_loss: 5397.4287 - val_mae: 52.5964\n",
      "Epoch 85/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1026.0327 - mae: 20.5417 - val_loss: 5429.0723 - val_mae: 53.1597\n",
      "Epoch 86/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1123.3356 - mae: 20.7781 - val_loss: 5422.3120 - val_mae: 52.2745\n",
      "Epoch 87/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1094.4669 - mae: 21.0668 - val_loss: 5336.1987 - val_mae: 51.8400\n",
      "Epoch 88/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1039.5093 - mae: 20.2386 - val_loss: 5409.2612 - val_mae: 52.0750\n",
      "Epoch 89/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1055.9254 - mae: 20.4178 - val_loss: 5318.7095 - val_mae: 51.7340\n",
      "Epoch 90/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 966.1113 - mae: 19.8899 - val_loss: 5370.9902 - val_mae: 51.6832\n",
      "Epoch 91/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1064.6641 - mae: 20.4712 - val_loss: 5401.3643 - val_mae: 52.3027\n",
      "Epoch 92/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1042.0721 - mae: 20.4075 - val_loss: 5341.6265 - val_mae: 51.5287\n",
      "Epoch 93/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1026.8903 - mae: 20.2422 - val_loss: 5324.3877 - val_mae: 51.5509\n",
      "Epoch 94/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 951.9852 - mae: 19.7707 - val_loss: 5433.7148 - val_mae: 52.0136\n",
      "Epoch 95/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1120.0513 - mae: 20.5191 - val_loss: 5267.1040 - val_mae: 51.6151\n",
      "Epoch 96/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1010.8959 - mae: 20.0652 - val_loss: 5334.3364 - val_mae: 51.5229\n",
      "Epoch 97/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1016.3431 - mae: 20.0119 - val_loss: 5216.6006 - val_mae: 51.1723\n",
      "Epoch 98/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 933.0440 - mae: 19.5746 - val_loss: 5302.2119 - val_mae: 52.0380\n",
      "Epoch 99/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 992.1901 - mae: 20.0587 - val_loss: 5246.7607 - val_mae: 51.4737\n",
      "Epoch 100/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 972.6831 - mae: 19.4439 - val_loss: 5207.1255 - val_mae: 51.1826\n",
      "\n",
      "Training finished (eindelijk)\n"
     ]
    }
   ],
   "source": [
    "#training \n",
    "\n",
    "history = model.fit(\n",
    "    X_train_processed, \n",
    "    y_train, \n",
    "    epochs = 100, \n",
    "    batch_size = 32, \n",
    "    validation_data = (X_val_processed, y_val)\n",
    "    #verbose = 0 #to hide data being trained\n",
    ")\n",
    "\n",
    "print(\"\\nTraining finished (eindelijk)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be7e4968-236c-4ac4-b06d-d6fc604bf5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Deep Learning Model Test Set RMSE: 78.05 rentals \n",
      "\n",
      "            Comparison\n",
      "Linear Regression RMSE: 144.00 rentals \n",
      "Deep Learning RMSE:     78.05 rentals\n"
     ]
    }
   ],
   "source": [
    "#evaluation + comparing (w RMSE)\n",
    "\n",
    "Y_pred = model.predict(X_test_processed)\n",
    "rmse_nn = np.sqrt(mean_squared_error(y_test, Y_pred))\n",
    "print(f\"Deep Learning Model Test Set RMSE: {rmse_nn:.2f} rentals \")\n",
    "\n",
    "rmse_linear_regression = 144 #other model\n",
    "print(\"\\n            Comparison\")\n",
    "print(f\"Linear Regression RMSE: {rmse_linear_regression:.2f} rentals \")\n",
    "print(f\"Deep Learning RMSE:     {rmse_nn:.2f} rentals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ca649-8c0e-4f5d-ad10-681b5ccf43ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
